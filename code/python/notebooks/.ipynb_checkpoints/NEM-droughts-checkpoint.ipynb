{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa7b3652-40db-46e3-8a89-40319096eeb4",
   "metadata": {},
   "source": [
    "# Time series for aggregated area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab84168b-3870-4725-a22d-0dd6ab220707",
   "metadata": {},
   "source": [
    "Read himawari data, apply the solar PV model, and save the mean value for each time step.\n",
    "Hence, output is a 1D time series of PV generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ea292d-0822-4b83-b15e-880fecc39b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/548/cd3022/aus-historical-solar-droughts/code/python/scripts')\n",
    "# sys.path.append('/home/548/pag548/code/aus-historical-solar-droughts/code/python/scripts')\n",
    "import utils\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550ea7ef-f341-48d6-b79c-5d02e8c0eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = sys.argv[1]\n",
    "end_date = sys.argv[2]\n",
    "\n",
    "# start_date = '1-2-2022'\n",
    "# end_date = '2-2-2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35d8488-089b-4a4e-abae-d2860247ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REZ mask\n",
    "mask_file = \"/home/548/cd3022/aus-historical-solar-droughts/data/boundary_files/REZ_mask.npz\"\n",
    "loaded_mask = np.load(mask_file)\n",
    "mask = loaded_mask[\"mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10cd882a-457f-4000-92fe-16740410a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = datetime.strptime(start_date, \"%d-%m-%Y\")\n",
    "end_dt = datetime.strptime(end_date, \"%d-%m-%Y\")\n",
    "\n",
    "# Generate a list of dates\n",
    "date_range = [start_dt + timedelta(days=i) for i in range((end_dt - start_dt).days + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1063935-9b55-4c2f-9400-7b91b919668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for time series\n",
    "NEM_performance = []\n",
    "# loop through all files in date range\n",
    "for dir_dt in date_range:\n",
    "\n",
    "    dataset = utils.get_irradiance_day(resolution='p1s', dir_dt=dir_dt)\n",
    "\n",
    "    # apply REZ mask to lat/lon coordinates\n",
    "    mask_da = xr.DataArray(mask, coords={\"latitude\": dataset.latitude, \"longitude\": dataset.longitude}, dims=[\"latitude\", \"longitude\"])\n",
    "    masked_ds = dataset.where(mask_da, drop=True)\n",
    "\n",
    "    # get irradiance data, ensuring to flatten and remove all unnecessary nan values\n",
    "    ghi = masked_ds.surface_global_irradiance.values.ravel()\n",
    "    dni = masked_ds.direct_normal_irradiance.values.ravel()\n",
    "    dhi = masked_ds.surface_diffuse_irradiance.values.ravel()\n",
    "    nan_mask = np.isnan(ghi) # same for all vars\n",
    "    ghi_clean = ghi[~nan_mask]\n",
    "    dni_clean = dni[~nan_mask]\n",
    "    dhi_clean = dhi[~nan_mask]\n",
    "\n",
    "    # get correct time and coordinate data, so that it matches up with the remaining irradiance values\n",
    "    lat_1d = masked_ds.latitude.values\n",
    "    lon_1d = masked_ds.longitude.values\n",
    "    lon_grid, lat_grid = np.meshgrid(lon_1d, lat_1d, indexing=\"xy\")\n",
    "    lat_grid_1d = lat_grid.ravel()\n",
    "    lon_grid_1d = lon_grid.ravel()\n",
    "    lat_1d_expanded = np.tile(lat_grid_1d, dataset.sizes[\"time\"])  # Tile lat for all times\n",
    "    lon_1d_expanded = np.tile(lon_grid_1d, dataset.sizes[\"time\"])  # Tile lon for all times\n",
    "    time_1d = np.repeat(masked_ds.time.values, len(lat_grid_1d))  # Repeat time for all lat/lon\n",
    "    lat_1d_expanded_clean = lat_1d_expanded[~nan_mask]\n",
    "    lon_1d_expanded_clean = lon_1d_expanded[~nan_mask]\n",
    "    time_1d_clean = time_1d[~nan_mask]\n",
    "\n",
    "    dataset.close()\n",
    "        \n",
    "    # calculate capacity factors using pvlib\n",
    "    # the function defined in utils_V2 is essentially the same as the workflow in pv-output-tilting.ipynb\n",
    "    actual_ideal_ratio = utils.tilting_panel_pr(\n",
    "        pv_model = 'Canadian_Solar_CS5P_220M___2009_',\n",
    "        inverter_model = 'ABB__MICRO_0_25_I_OUTD_US_208__208V_',\n",
    "        ghi=ghi_clean,\n",
    "        dni=dni_clean,\n",
    "        dhi=dhi_clean,\n",
    "        time=time_1d_clean,\n",
    "        lat=lat_1d_expanded_clean,\n",
    "        lon=lon_1d_expanded_clean\n",
    "    )  \n",
    "\n",
    "    # template to refit data to\n",
    "    mask_template = masked_ds.surface_global_irradiance\n",
    "    \n",
    "    # Now need to get data back in line with coordinates\n",
    "    # fill cf array with nan values so it can fit back into lat/lon coords\n",
    "    filled = np.empty_like(ghi)\n",
    "    # nan values outside the data\n",
    "    filled[nan_mask] = np.nan\n",
    "    # add the data to the same mask the input irradiance data was taken from\n",
    "    filled[~nan_mask] = actual_ideal_ratio\n",
    "    # convert data back into 3D xarray\n",
    "    reshaped = filled.reshape(mask_template.shape)\n",
    "    ratio_da = xr.DataArray(reshaped, coords=mask_template.coords, dims=mask_template.dims)\n",
    "\n",
    "    # get mean for each time slice and add it to the list\n",
    "    mean_daily = ratio_da.mean(dim=[\"latitude\", \"longitude\"], skipna=True)\n",
    "    NEM_performance.append(mean_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2771af3c-d9f7-4f53-b87b-a7050fa6b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEM_performance_timeseries = xr.concat(NEM_performance, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17270c28-8f98-4093-9139-3b68942a2f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/g/data/er8/users/cd3022/solar_drought/REZ_tilting/ideal_ratio/NEM_timeseries'\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "NEM_performance_timeseries.to_netcdf(f'{file_path}/{start_date}___{end_date}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6331db21-f390-4edf-b464-fa2f213dba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook /home/548/cd3022/aus-historical-solar-droughts/code/python/notebooks/NEM-droughts.ipynb to script\n",
      "[NbConvertApp] Writing 4650 bytes to /home/548/cd3022/aus-historical-solar-droughts/code/python/scripts/NEM-droughts.py\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    NOTEBOOK_PATH=\"/home/548/cd3022/aus-historical-solar-droughts/code/python/notebooks/NEM-droughts.ipynb\"\n",
    "    SCRIPT_PATH=\"/home/548/cd3022/aus-historical-solar-droughts/code/python/scripts/NEM-droughts\"\n",
    "    \n",
    "    !jupyter nbconvert --to script {NOTEBOOK_PATH} --output {SCRIPT_PATH}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
