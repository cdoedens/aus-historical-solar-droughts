{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa7b3652-40db-46e3-8a89-40319096eeb4",
   "metadata": {},
   "source": [
    "# Time series for aggregated area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab84168b-3870-4725-a22d-0dd6ab220707",
   "metadata": {},
   "source": [
    "Read himawari data, apply the solar PV model, and save the mean value for each time step.\n",
    "Hence, output is a 1D time series of PV generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ea292d-0822-4b83-b15e-880fecc39b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /g/data/hh5/public/apps/miniconda3/envs/analysis3-24.04/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/548/cd3022/aus-historical-solar-droughts/code/python/scripts')\n",
    "# sys.path.append('/home/548/pag548/code/aus-historical-solar-droughts/code/python/scripts')\n",
    "import utils\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "import odc.geo.xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550ea7ef-f341-48d6-b79c-5d02e8c0eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = sys.argv[1]\n",
    "# end_date = sys.argv[2]\n",
    "\n",
    "start_date = '1-2-2022'\n",
    "end_date = '1-2-2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35d8488-089b-4a4e-abae-d2860247ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REZ mask\n",
    "shapefile = '/home/548/cd3022/aus-historical-solar-droughts/data/boundary_files/REZ-boundaries.shx'\n",
    "gdf = gpd.read_file(shapefile)\n",
    "\n",
    "zones_to_ignore = [ # only wind farms in zone, no solar\n",
    "    'Q1',\n",
    "    'N7',\n",
    "    'N8',\n",
    "    'N10',\n",
    "    'N11',\n",
    "    'V3',\n",
    "    'V4',\n",
    "    'V7',\n",
    "    'V8',\n",
    "    'T4',\n",
    "    'S1',\n",
    "    'S3',\n",
    "    'S4',\n",
    "    'S5',\n",
    "    'S10'\n",
    "]\n",
    "\n",
    "gdf = gdf[~gdf[\"Name\"].str[:2].isin(zones_to_ignore)]\n",
    "\n",
    "VIC = gdf[gdf[\"Name\"].str.startswith(\"V\")]\n",
    "\n",
    "region = gdf\n",
    "\n",
    "lon_min, lat_min, lon_max, lat_max = region.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8176ec81-7a65-4425-98e3-8232e6a82951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess(ds):\n",
    "    return ds[\n",
    "    ['surface_global_irradiance', 'direct_normal_irradiance', 'surface_diffuse_irradiance']\n",
    "    ].sel(latitude=slice(lat_min, lat_max), longitude=slice(lon_min, lon_max))\n",
    "\n",
    "def read_data(date):\n",
    "    # get correct file path based on the date\n",
    "    dir_dt = datetime.strptime(date, \"%Y/%m/%d\")\n",
    "    if dir_dt <= datetime.strptime('2019-03-31', '%Y-%m-%d'):\n",
    "        version = 'v1.0'\n",
    "    else:\n",
    "        version = 'v1.1'\n",
    "\n",
    "    # read all files in the subdirectory based on the date passed\n",
    "    directory=Path(f'/g/data/rv74/satellite-products/arc/der/himawari-ahi/solar/p1s/{version}/{date}')\n",
    "    files = list(directory.rglob(\"*.nc\"))\n",
    "    ds = xr.open_mfdataset(files, parallel=True, preprocess=_preprocess)\n",
    "    ds = ds.chunk({'time':100, 'latitude':500, 'longitude':500})\n",
    "\n",
    "    # apply mask\n",
    "    mask = rasterio.features.geometry_mask(\n",
    "                region.geometry,\n",
    "                out_shape=ds.odc.geobox.shape,\n",
    "                transform=ds.odc.geobox.affine,\n",
    "                all_touched=False,\n",
    "                invert=False)\n",
    "    mask = xr.DataArray(~mask, dims=('latitude', 'longitude'),coords=dict(\n",
    "            longitude=ds.longitude,\n",
    "            latitude=ds.latitude)\n",
    "                       ).chunk({'latitude': 500, 'longitude': 500})\n",
    "    masked_ds = ds.where(mask)\n",
    "    \n",
    "    return masked_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10cd882a-457f-4000-92fe-16740410a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = datetime.strptime(start_date, \"%d-%m-%Y\")\n",
    "end_dt = datetime.strptime(end_date, \"%d-%m-%Y\")\n",
    "\n",
    "# Generate a list of dates\n",
    "date_range = [start_dt + timedelta(days=i) for i in range((end_dt - start_dt).days + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1063935-9b55-4c2f-9400-7b91b919668a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m lon_1d_expanded_clean \u001b[38;5;241m=\u001b[39m lon_1d_expanded[\u001b[38;5;241m~\u001b[39mnan_mask]\n\u001b[1;32m     29\u001b[0m time_1d_clean \u001b[38;5;241m=\u001b[39m time_1d[\u001b[38;5;241m~\u001b[39mnan_mask]\n\u001b[0;32m---> 31\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# calculate capacity factors using pvlib\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# the function defined in utils_V2 is essentially the same as the workflow in pv-output-tilting.ipynb\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m###################################\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# TILTING_PANEL_PR CURRENTLY RETURNING ACUTAL GENERATION, NOT IDEAL RATIO\u001b[39;00m\n\u001b[1;32m     37\u001b[0m actual_ideal_ratio \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mtilting_panel_pr(\n\u001b[1;32m     38\u001b[0m     pv_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCanadian_Solar_CS5P_220M___2009_\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     39\u001b[0m     inverter_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mABB__MICRO_0_25_I_OUTD_US_208__208V_\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     lon\u001b[38;5;241m=\u001b[39mlon_1d_expanded_clean\n\u001b[1;32m     46\u001b[0m )  \n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# list for time series\n",
    "NEM_performance = []\n",
    "# loop through all files in date range\n",
    "for dir_dt in date_range:\n",
    "    \n",
    "    date = dir_dt.strftime('%Y/%m/%d')\n",
    "    ds = read_data(date)\n",
    "\n",
    "    # get irradiance data, ensuring to flatten and remove all unnecessary nan values\n",
    "    ghi = ds.surface_global_irradiance.values.ravel()\n",
    "    dni = ds.direct_normal_irradiance.values.ravel()\n",
    "    dhi = ds.surface_diffuse_irradiance.values.ravel()\n",
    "    nan_mask = np.isnan(ghi) # same for all vars\n",
    "    ghi_clean = ghi[~nan_mask]\n",
    "    dni_clean = dni[~nan_mask]\n",
    "    dhi_clean = dhi[~nan_mask]\n",
    "\n",
    "    # get correct time and coordinate data, so that it matches up with the remaining irradiance values\n",
    "    lat_1d = ds.latitude.values\n",
    "    lon_1d = ds.longitude.values\n",
    "    lon_grid, lat_grid = np.meshgrid(lon_1d, lat_1d, indexing=\"xy\")\n",
    "    lat_grid_1d = lat_grid.ravel()\n",
    "    lon_grid_1d = lon_grid.ravel()\n",
    "    lat_1d_expanded = np.tile(lat_grid_1d, ds.sizes[\"time\"])  # Tile lat for all times\n",
    "    lon_1d_expanded = np.tile(lon_grid_1d, ds.sizes[\"time\"])  # Tile lon for all times\n",
    "    time_1d = np.repeat(ds.time.values, len(lat_grid_1d))  # Repeat time for all lat/lon\n",
    "    lat_1d_expanded_clean = lat_1d_expanded[~nan_mask]\n",
    "    lon_1d_expanded_clean = lon_1d_expanded[~nan_mask]\n",
    "    time_1d_clean = time_1d[~nan_mask]\n",
    "\n",
    "    dataset.close()\n",
    "        \n",
    "    # calculate capacity factors using pvlib\n",
    "    # the function defined in utils_V2 is essentially the same as the workflow in pv-output-tilting.ipynb\n",
    "    ###################################\n",
    "    # TILTING_PANEL_PR CURRENTLY RETURNING ACUTAL GENERATION, NOT IDEAL RATIO\n",
    "    actual_ideal_ratio = utils.tilting_panel_pr(\n",
    "        pv_model = 'Canadian_Solar_CS5P_220M___2009_',\n",
    "        inverter_model = 'ABB__MICRO_0_25_I_OUTD_US_208__208V_',\n",
    "        ghi=ghi_clean,\n",
    "        dni=dni_clean,\n",
    "        dhi=dhi_clean,\n",
    "        time=time_1d_clean,\n",
    "        lat=lat_1d_expanded_clean,\n",
    "        lon=lon_1d_expanded_clean\n",
    "    )  \n",
    "\n",
    "    # template to refit data to\n",
    "    mask_template = ds.surface_global_irradiance\n",
    "    \n",
    "    # Now need to get data back in line with coordinates\n",
    "    # fill cf array with nan values so it can fit back into lat/lon coords\n",
    "    filled = np.empty_like(ghi)\n",
    "    # nan values outside the data\n",
    "    filled[nan_mask] = np.nan\n",
    "    # add the data to the same mask the input irradiance data was taken from\n",
    "    filled[~nan_mask] = actual_ideal_ratio\n",
    "    # convert data back into 3D xarray\n",
    "    reshaped = filled.reshape(mask_template.shape)\n",
    "    ratio_da = xr.DataArray(reshaped, coords=mask_template.coords, dims=mask_template.dims)\n",
    "\n",
    "    # get mean for each time slice and add it to the list\n",
    "    mean_daily = ratio_da.mean(dim=[\"latitude\", \"longitude\"], skipna=True)\n",
    "    NEM_performance.append(mean_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2771af3c-d9f7-4f53-b87b-a7050fa6b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEM_performance_timeseries = xr.concat(NEM_performance, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17270c28-8f98-4093-9139-3b68942a2f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/g/data/er8/users/cd3022/solar_drought/REZ_tilting/ideal_ratio/NEM_timeseries'\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "NEM_performance_timeseries.to_netcdf(f'{file_path}/{start_date}___{end_date}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6331db21-f390-4edf-b464-fa2f213dba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    NOTEBOOK_PATH=\"/home/548/cd3022/aus-historical-solar-droughts/code/python/notebooks/NEM-droughts.ipynb\"\n",
    "    SCRIPT_PATH=\"/home/548/cd3022/aus-historical-solar-droughts/code/python/scripts/NEM-droughts\"\n",
    "    \n",
    "    !jupyter nbconvert --to script {NOTEBOOK_PATH} --output {SCRIPT_PATH}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
